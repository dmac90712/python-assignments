{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Assignment Module 8 Lab 1: Predicting House Prices in California using Linear Regression\n",
    "\n",
    "### Background\n",
    "\n",
    "Accurately predicting house prices is essential in the real estate market. In this assignment, you will use linear regression to predict house prices based on various features such as the number of rooms, population density, and median income in different neighborhoods in California.\n",
    "\n",
    "### Dataset\n",
    "\n",
    "The dataset you will be using is the California Housing dataset, which contains information about houses in different locations in California. The dataset includes 20,640 observations and 8 variables, including:\n",
    "\n",
    "- `MedInc`: Median income in the block\n",
    "- `HouseAge`: Median house age in the block\n",
    "- `AveRooms`: Average number of rooms per dwelling\n",
    "- `AveBedrms`: Average number of bedrooms per dwelling\n",
    "- `Population`: Block population\n",
    "- `AveOccup`: Average house occupancy\n",
    "- `Latitude`: Latitude coordinate of the block\n",
    "- `Longitude`: Longitude coordinate of the block\n",
    "\n",
    "You can load the dataset using the following code:\n",
    "\n",
    "```python\n",
    "from sklearn.datasets import fetch_california_housing\n",
    "\n",
    "# Load the California Housing dataset\n",
    "california = fetch_california_housing(as_frame=True)\n",
    "\n",
    "# Access the data and target variables\n",
    "X = california.data\n",
    "y = california.target\n",
    "```\n",
    "\n",
    "### Task\n",
    "\n",
    "Your task is to predict house prices in California using linear regression. You will need to perform the following steps:\n",
    "\n",
    "1. Load the California Housing dataset into a Pandas DataFrame.\n",
    "2. Split the dataset into training and testing sets, with a 70/30 split.\n",
    "3. Fit a `LinearRegression` model to the training data.\n",
    "4. Predict house prices for the testing set.\n",
    "5. Evaluate the performance of the model using the following error checking metrics:\n",
    "   - R-squared (R2)\n",
    "   - Mean Squared Error (MSE)\n",
    "   - Mean Absolute Error (MAE)\n",
    "   - Akaike Information Criterion (AIC)\n",
    "6. Analyze the performance of the model and provide recommendations for improvement.\n",
    "\n",
    "You can use the `OLS` (ordinary least squares) method from the `statsmodels.regression.linear_model` module to calculate the Akaike Information Criterion (AIC).\n",
    "\n",
    "### Submission Instructions\n",
    "\n",
    "Please submit a Jupyter notebook containing your code, output, and analysis. Make sure to include the following sections in your notebook:\n",
    "\n",
    "1. Introduction\n",
    "2. Dataset Description\n",
    "3. Data Preprocessing\n",
    "4. Model Training\n",
    "5. Model Evaluation\n",
    "6. Performance Analysis and Recommendations\n",
    "7. Conclusion\n",
    "\n",
    "Your notebook should be well-documented and easy to follow, with clear explanations of the steps you took and the results you obtained. Make sure to comment your code and include markdown cells explaining your thought process and conclusions. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CS82B ‚Äì Principles of Data Science  \n",
    "## Module 8 ‚Äì Lab 1  \n",
    "**Student Name**: Derek McCrary  \n",
    "**Due Date**: May 25, 2025"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import fetch_california_housing\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "california = fetch_california_housing(as_frame=True)\n",
    "X = california.data\n",
    "y = california.target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((14448, 8), (6192, 8))"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Split dataset: 70% training, 30% testing\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "\n",
    "# Confirm shapes\n",
    "X_train.shape, X_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "import pandas as pd\n",
    "\n",
    "# Standardize and preserve column names\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = pd.DataFrame(scaler.fit_transform(X_train), columns=X.columns, index=X_train.index)\n",
    "X_test_scaled = pd.DataFrame(scaler.transform(X_test), columns=X.columns, index=X_test.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sanity check: drop rows with invalid data from scaled sets\n",
    "X_train_scaled = X_train_scaled.replace([np.inf, -np.inf], np.nan).dropna()\n",
    "X_test_scaled = X_test_scaled.replace([np.inf, -np.inf], np.nan).dropna()\n",
    "\n",
    "# Also filter y_train and y_test to match the new index\n",
    "y_train = y_train.loc[X_train_scaled.index]\n",
    "y_test = y_test.loc[X_test_scaled.index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R¬≤ Score: 0.596\n",
      "Mean Squared Error (MSE): 0.53\n",
      "Mean Absolute Error (MAE): 0.53\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import r2_score, mean_squared_error, mean_absolute_error\n",
    "\n",
    "# Evaluate model\n",
    "r2 = r2_score(y_test, y_pred)\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "mae = mean_absolute_error(y_test, y_pred)\n",
    "\n",
    "print(f\"R¬≤ Score: {r2:.3f}\")\n",
    "print(f\"Mean Squared Error (MSE): {mse:.2f}\")\n",
    "print(f\"Mean Absolute Error (MAE): {mae:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R¬≤ Score: 0.596\n",
      "Mean Squared Error (MSE): 0.53\n",
      "Mean Absolute Error (MAE): 0.53\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Volumes/DevDereks/opt/anaconda3/envs/jupyter_env/lib/python3.11/site-packages/sklearn/linear_model/_base.py:279: RuntimeWarning: divide by zero encountered in matmul\n",
      "  return X @ coef_ + self.intercept_\n",
      "/Volumes/DevDereks/opt/anaconda3/envs/jupyter_env/lib/python3.11/site-packages/sklearn/linear_model/_base.py:279: RuntimeWarning: overflow encountered in matmul\n",
      "  return X @ coef_ + self.intercept_\n",
      "/Volumes/DevDereks/opt/anaconda3/envs/jupyter_env/lib/python3.11/site-packages/sklearn/linear_model/_base.py:279: RuntimeWarning: invalid value encountered in matmul\n",
      "  return X @ coef_ + self.intercept_\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import r2_score, mean_squared_error, mean_absolute_error\n",
    "\n",
    "# Make predictions\n",
    "# üîç Predict using scaled test set\n",
    "y_pred = model.predict(X_test_scaled)\n",
    "\n",
    "# Calculate metrics\n",
    "r2 = r2_score(y_test, y_pred)\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "mae = mean_absolute_error(y_test, y_pred)\n",
    "\n",
    "print(f\"R¬≤ Score: {r2:.3f}\")\n",
    "print(f\"Mean Squared Error (MSE): {mse:.2f}\")\n",
    "print(f\"Mean Absolute Error (MAE): {mae:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R¬≤ Score: 0.596\n",
      "Mean Squared Error (MSE): 0.53\n",
      "Mean Absolute Error (MAE): 0.53\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Volumes/DevDereks/opt/anaconda3/envs/jupyter_env/lib/python3.11/site-packages/sklearn/linear_model/_base.py:279: RuntimeWarning: divide by zero encountered in matmul\n",
      "  return X @ coef_ + self.intercept_\n",
      "/Volumes/DevDereks/opt/anaconda3/envs/jupyter_env/lib/python3.11/site-packages/sklearn/linear_model/_base.py:279: RuntimeWarning: overflow encountered in matmul\n",
      "  return X @ coef_ + self.intercept_\n",
      "/Volumes/DevDereks/opt/anaconda3/envs/jupyter_env/lib/python3.11/site-packages/sklearn/linear_model/_base.py:279: RuntimeWarning: invalid value encountered in matmul\n",
      "  return X @ coef_ + self.intercept_\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import r2_score, mean_squared_error, mean_absolute_error\n",
    "\n",
    "# Make predictions\n",
    "# üîç Predict using scaled test set\n",
    "y_pred = model.predict(X_test_scaled)\n",
    "\n",
    "# Calculate metrics\n",
    "r2 = r2_score(y_test, y_pred)\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "mae = mean_absolute_error(y_test, y_pred)\n",
    "\n",
    "print(f\"R¬≤ Score: {r2:.3f}\")\n",
    "print(f\"Mean Squared Error (MSE): {mse:.2f}\")\n",
    "print(f\"Mean Absolute Error (MAE): {mae:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NaNs in X_train_scaled: 0\n",
      "Infs in X_train_scaled: 0\n",
      "NaNs in X_test_scaled: 0\n",
      "Infs in X_test_scaled: 0\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Check for NaN or infinite values\n",
    "print(\"NaNs in X_train_scaled:\", np.isnan(X_train_scaled).sum().sum())\n",
    "print(\"Infs in X_train_scaled:\", np.isinf(X_train_scaled).sum().sum())\n",
    "print(\"NaNs in X_test_scaled:\", np.isnan(X_test_scaled).sum().sum())\n",
    "print(\"Infs in X_test_scaled:\", np.isinf(X_test_scaled).sum().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "y_train min: 0.14999\n",
      "y_train max: 5.00001\n",
      "y_test min: 0.14999\n",
      "y_test max: 5.00001\n",
      "Any NaNs in y_train: 0\n",
      "Any NaNs in y_test: 0\n"
     ]
    }
   ],
   "source": [
    "#  Target (y_train, y_test) range and null check\n",
    "print(\"y_train min:\", y_train.min())\n",
    "print(\"y_train max:\", y_train.max())\n",
    "print(\"y_test min:\", y_test.min())\n",
    "print(\"y_test max:\", y_test.max())\n",
    "print(\"Any NaNs in y_train:\", y_train.isna().sum())\n",
    "print(\"Any NaNs in y_test:\", y_test.isna().sum())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Volumes/DevDereks/opt/anaconda3/envs/jupyter_env/lib/python3.11/site-packages/sklearn/linear_model/_base.py:279: RuntimeWarning: divide by zero encountered in matmul\n",
      "  return X @ coef_ + self.intercept_\n",
      "/Volumes/DevDereks/opt/anaconda3/envs/jupyter_env/lib/python3.11/site-packages/sklearn/linear_model/_base.py:279: RuntimeWarning: overflow encountered in matmul\n",
      "  return X @ coef_ + self.intercept_\n",
      "/Volumes/DevDereks/opt/anaconda3/envs/jupyter_env/lib/python3.11/site-packages/sklearn/linear_model/_base.py:279: RuntimeWarning: invalid value encountered in matmul\n",
      "  return X @ coef_ + self.intercept_\n"
     ]
    }
   ],
   "source": [
    "# Model training and prediction\n",
    "model = LinearRegression()\n",
    "model.fit(X_train_scaled, y_train)  # Train on scaled data\n",
    "\n",
    "y_pred = model.predict(X_test_scaled)  # Predict on scaled data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AIC: 31664.71\n"
     ]
    }
   ],
   "source": [
    "# Final code block: AIC calculation\n",
    "import statsmodels.api as sm\n",
    "\n",
    "X_train_sm = sm.add_constant(X_train_scaled)\n",
    "ols_model = sm.OLS(y_train, X_train_sm).fit()\n",
    "\n",
    "print(f\"AIC: {ols_model.aic:.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üìä Conclusion\n",
    "\n",
    "In this lab, I built a linear regression model to predict California housing prices using features such as income, location, and occupancy. After preprocessing and splitting the dataset, I trained the model and evaluated its performance.\n",
    "\n",
    "### üìà Model Evaluation Metrics:\n",
    "- **R¬≤ Score**: 0.596  \n",
    "- **Mean Squared Error (MSE)**: 0.53  \n",
    "- **Mean Absolute Error (MAE)**: 0.53  \n",
    "- **Akaike Information Criterion (AIC)**: 31664.71\n",
    "\n",
    "### üîç Observations:\n",
    "- The model demonstrated moderate predictive power, explaining nearly 60% of the variance in housing prices.\n",
    "- All features were successfully scaled and validated (no NaNs or infinities).\n",
    "- Standardization ensured stable training and prediction.\n",
    "- AIC was used to assess model quality with respect to complexity.\n",
    "\n",
    "### ‚úÖ Recommendations:\n",
    "- Explore advanced models like Ridge or Lasso Regression.\n",
    "- Try feature engineering (e.g., interaction terms, log-transforming skewed variables).\n",
    "- Use cross-validation to further assess model generalizability."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üìä Conclusion\n",
    "\n",
    "In this lab, I built a linear regression model to predict California housing prices using features such as income, location, and occupancy. After preprocessing and splitting the dataset, I trained the model and evaluated its performance.\n",
    "\n",
    "### üìà Model Evaluation Metrics:\n",
    "- **R¬≤ Score**: 0.596  \n",
    "- **Mean Squared Error (MSE)**: 0.53  \n",
    "- **Mean Absolute Error (MAE)**: 0.53  \n",
    "- **Akaike Information Criterion (AIC)**: 31664.71\n",
    "\n",
    "### üîç Observations:\n",
    "- The model demonstrated moderate predictive power, explaining nearly 60% of the variance in housing prices.\n",
    "- All features were successfully scaled and validated (no NaNs or infinities).\n",
    "- Standardization ensured stable training and prediction.\n",
    "- AIC was used to assess model quality with respect to complexity.\n",
    "\n",
    "### ‚úÖ Recommendations:\n",
    "- Explore advanced models like Ridge or Lasso Regression.\n",
    "- Try feature engineering (e.g., interaction terms, log-transforming skewed variables).\n",
    "- Use cross-validation to further assess model generalizability."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "jupyter_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
